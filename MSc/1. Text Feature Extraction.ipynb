{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "678201c4",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5b8fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCENE</th>\n",
       "      <th>KEY</th>\n",
       "      <th>SENTENCE</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>SPEAKER</th>\n",
       "      <th>SHOW</th>\n",
       "      <th>Sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>1_10004_c_00</td>\n",
       "      <td>Well, I'm sure that, uh, you...\\nhave a lot of...</td>\n",
       "      <td>0:06</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>1_10004_c_01</td>\n",
       "      <td>Who was he?</td>\n",
       "      <td>0:08</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>1_10004_c_02</td>\n",
       "      <td>His name is Ron.\\nI met him at my prayer group.</td>\n",
       "      <td>0:12</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>1_10004_c_03</td>\n",
       "      <td>How long have you been involved with him?</td>\n",
       "      <td>0:14</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>1_10004_c_04</td>\n",
       "      <td>A few months.</td>\n",
       "      <td>0:16</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>1_10004_u</td>\n",
       "      <td>And of those few months, how long have you bee...</td>\n",
       "      <td>0:07</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_c_00</td>\n",
       "      <td>FYI, we plan on selling out the human race hard.</td>\n",
       "      <td>0:02</td>\n",
       "      <td>AMY</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_c_01</td>\n",
       "      <td>In 20 years, who knows what'll happen with any...</td>\n",
       "      <td>0:08</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_c_02</td>\n",
       "      <td>I think you and Leonard will be together.</td>\n",
       "      <td>0:1</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_c_03</td>\n",
       "      <td>You do?</td>\n",
       "      <td>0:11</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_c_04</td>\n",
       "      <td>Yeah.\\nI think you're the best couple I know.</td>\n",
       "      <td>0:15</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_c_05</td>\n",
       "      <td>That's so sweet.</td>\n",
       "      <td>0:16</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_c_06</td>\n",
       "      <td>What the hell?! Excuse me?</td>\n",
       "      <td>0:17</td>\n",
       "      <td>AMY</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_c_07</td>\n",
       "      <td>Ah-da-da-da-da!</td>\n",
       "      <td>0:2</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>1_10009_u</td>\n",
       "      <td>Let the dead man talk. So, why do you think that?</td>\n",
       "      <td>0:05</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1_1001</td>\n",
       "      <td>1_1001_c_00</td>\n",
       "      <td>Or maybe she just doesn't want to talk.</td>\n",
       "      <td>0:03</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1_1001</td>\n",
       "      <td>1_1001_c_01</td>\n",
       "      <td>Look, I found an iPod!</td>\n",
       "      <td>0:08</td>\n",
       "      <td>RAJ</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1_1001</td>\n",
       "      <td>1_1001_c_02</td>\n",
       "      <td>It's smashed beyond repair. What are you gonna...</td>\n",
       "      <td>0:15</td>\n",
       "      <td>HOWARD</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1_1001</td>\n",
       "      <td>1_1001_u</td>\n",
       "      <td>What else? Sell it on eBay as \"slightly used.\"</td>\n",
       "      <td>0:04</td>\n",
       "      <td>RAJ</td>\n",
       "      <td>BBT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1_1003</td>\n",
       "      <td>1_1003_c_00</td>\n",
       "      <td>It's smashed beyond repair. What are you gonna...</td>\n",
       "      <td>0:03</td>\n",
       "      <td>HOWARD</td>\n",
       "      <td>BBT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SCENE           KEY                                           SENTENCE   \n",
       "0   1_10004  1_10004_c_00  Well, I'm sure that, uh, you...\\nhave a lot of...  \\\n",
       "1   1_10004  1_10004_c_01                                        Who was he?   \n",
       "2   1_10004  1_10004_c_02    His name is Ron.\\nI met him at my prayer group.   \n",
       "3   1_10004  1_10004_c_03          How long have you been involved with him?   \n",
       "4   1_10004  1_10004_c_04                                      A few months.   \n",
       "5   1_10004     1_10004_u  And of those few months, how long have you bee...   \n",
       "6   1_10009  1_10009_c_00   FYI, we plan on selling out the human race hard.   \n",
       "7   1_10009  1_10009_c_01  In 20 years, who knows what'll happen with any...   \n",
       "8   1_10009  1_10009_c_02          I think you and Leonard will be together.   \n",
       "9   1_10009  1_10009_c_03                                            You do?   \n",
       "10  1_10009  1_10009_c_04      Yeah.\\nI think you're the best couple I know.   \n",
       "11  1_10009  1_10009_c_05                                   That's so sweet.   \n",
       "12  1_10009  1_10009_c_06                         What the hell?! Excuse me?   \n",
       "13  1_10009  1_10009_c_07                                    Ah-da-da-da-da!   \n",
       "14  1_10009     1_10009_u  Let the dead man talk. So, why do you think that?   \n",
       "15   1_1001   1_1001_c_00            Or maybe she just doesn't want to talk.   \n",
       "16   1_1001   1_1001_c_01                             Look, I found an iPod!   \n",
       "17   1_1001   1_1001_c_02  It's smashed beyond repair. What are you gonna...   \n",
       "18   1_1001      1_1001_u     What else? Sell it on eBay as \"slightly used.\"   \n",
       "19   1_1003   1_1003_c_00  It's smashed beyond repair. What are you gonna...   \n",
       "\n",
       "   END_TIME  SPEAKER SHOW  Sarcasm  \n",
       "0      0:06   PERSON  BBT      NaN  \n",
       "1      0:08  SHELDON  BBT      NaN  \n",
       "2      0:12   PERSON  BBT      NaN  \n",
       "3      0:14  SHELDON  BBT      NaN  \n",
       "4      0:16   PERSON  BBT      NaN  \n",
       "5      0:07  SHELDON  BBT      0.0  \n",
       "6      0:02      AMY  BBT      NaN  \n",
       "7      0:08    PENNY  BBT      NaN  \n",
       "8       0:1   PERSON  BBT      NaN  \n",
       "9      0:11    PENNY  BBT      NaN  \n",
       "10     0:15   PERSON  BBT      NaN  \n",
       "11     0:16    PENNY  BBT      NaN  \n",
       "12     0:17      AMY  BBT      NaN  \n",
       "13      0:2    PENNY  BBT      NaN  \n",
       "14     0:05    PENNY  BBT      0.0  \n",
       "15     0:03  SHELDON  BBT      NaN  \n",
       "16     0:08      RAJ  BBT      NaN  \n",
       "17     0:15   HOWARD  BBT      NaN  \n",
       "18     0:04      RAJ  BBT      0.0  \n",
       "19     0:03   HOWARD  BBT      NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"mustard++/dataframe.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.iloc[:, :-5]\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57cd52c",
   "metadata": {},
   "source": [
    "# Preprocess data\n",
    "Creating a dataframe with two columns such that one column is concatenated context and another column is the utterance text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e32fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCENE</th>\n",
       "      <th>SENTENCE_A</th>\n",
       "      <th>SENTENCE_B</th>\n",
       "      <th>Sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>[CLS] PERSON: Well, I'm sure that, uh, you...h...</td>\n",
       "      <td>[SEP] SHELDON: And of those few months, how l...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>[CLS] AMY: FYI, we plan on selling out the hum...</td>\n",
       "      <td>[SEP] PENNY: Let the dead man talk. So, why d...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_1001</td>\n",
       "      <td>[CLS] SHELDON: Or maybe she just doesn't want ...</td>\n",
       "      <td>[SEP] RAJ: What else? Sell it on eBay as \"sli...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_1003</td>\n",
       "      <td>[CLS] HOWARD: It's smashed beyond repair. What...</td>\n",
       "      <td>[SEP] HOWARD: Good idea, sit with her. Hold h...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_10190</td>\n",
       "      <td>[CLS] PENNY: it's important to the story that ...</td>\n",
       "      <td>[SEP] SHELDON: Well, now that I've given up s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>3_S06E02_398</td>\n",
       "      <td>[CLS] -: There's a reason Jared tried to ditch...</td>\n",
       "      <td>[SEP] OTHER: Look, we cannot take blood money...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>3_S06E03_366</td>\n",
       "      <td>[CLS] RICHARD: You guys, there's really no oth...</td>\n",
       "      <td>[SEP] RICHARD: The-the same way we can buy Am...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>3_S06E05_355</td>\n",
       "      <td>[CLS] MONICA: -What? -Sorry. I just, um, [SEP]...</td>\n",
       "      <td>[SEP] OTHER: Well, maybe some time when you'r...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>3_S06E06_143</td>\n",
       "      <td>[CLS] GILFOYLE: Based on the amount of work le...</td>\n",
       "      <td>[SEP] GILFOYLE: I thought that was the compan...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>3_S06E07_272</td>\n",
       "      <td>[CLS] GILFOYLE: When Richard told me about the...</td>\n",
       "      <td>[SEP] DINESH: That you're an alcoholic? [SEP]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1202 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             SCENE                                         SENTENCE_A   \n",
       "0          1_10004  [CLS] PERSON: Well, I'm sure that, uh, you...h...  \\\n",
       "1          1_10009  [CLS] AMY: FYI, we plan on selling out the hum...   \n",
       "2           1_1001  [CLS] SHELDON: Or maybe she just doesn't want ...   \n",
       "3           1_1003  [CLS] HOWARD: It's smashed beyond repair. What...   \n",
       "4          1_10190  [CLS] PENNY: it's important to the story that ...   \n",
       "...            ...                                                ...   \n",
       "1197  3_S06E02_398  [CLS] -: There's a reason Jared tried to ditch...   \n",
       "1198  3_S06E03_366  [CLS] RICHARD: You guys, there's really no oth...   \n",
       "1199  3_S06E05_355  [CLS] MONICA: -What? -Sorry. I just, um, [SEP]...   \n",
       "1200  3_S06E06_143  [CLS] GILFOYLE: Based on the amount of work le...   \n",
       "1201  3_S06E07_272  [CLS] GILFOYLE: When Richard told me about the...   \n",
       "\n",
       "                                             SENTENCE_B  Sarcasm  \n",
       "0      [SEP] SHELDON: And of those few months, how l...      0.0  \n",
       "1      [SEP] PENNY: Let the dead man talk. So, why d...      0.0  \n",
       "2      [SEP] RAJ: What else? Sell it on eBay as \"sli...      0.0  \n",
       "3      [SEP] HOWARD: Good idea, sit with her. Hold h...      1.0  \n",
       "4      [SEP] SHELDON: Well, now that I've given up s...      0.0  \n",
       "...                                                 ...      ...  \n",
       "1197   [SEP] OTHER: Look, we cannot take blood money...      0.0  \n",
       "1198   [SEP] RICHARD: The-the same way we can buy Am...      1.0  \n",
       "1199   [SEP] OTHER: Well, maybe some time when you'r...      1.0  \n",
       "1200   [SEP] GILFOYLE: I thought that was the compan...      1.0  \n",
       "1201      [SEP] DINESH: That you're an alcoholic? [SEP]      1.0  \n",
       "\n",
       "[1202 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = df.sort_values(['SCENE', 'KEY'])\n",
    "\n",
    "df['SPEAKER_SENTENCE'] = df['SPEAKER'] + ': ' + df['SENTENCE']\n",
    "\n",
    "# Create a new dataframe for the transformed data\n",
    "df_new = pd.DataFrame(columns = ['SCENE', 'SENTENCE_A', 'SENTENCE_B', 'Sarcasm'])\n",
    "\n",
    "prev_scene = ''\n",
    "sentence_a = ''\n",
    "sentence_b = ''\n",
    "sarcasm_label = None\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['SCENE'] != prev_scene:\n",
    "        # new conversation starts\n",
    "        sentence_a = '[CLS] ' + row['SPEAKER_SENTENCE']\n",
    "        sentence_b = ''\n",
    "    elif 'c' in row['KEY']:\n",
    "        # same conversation, add to context\n",
    "        sentence_a += ' [SEP] ' + row['SPEAKER_SENTENCE']\n",
    "    elif 'u' in row['KEY']:\n",
    "        # it's the utterance sentence\n",
    "        sentence_b = ' [SEP] ' + row['SPEAKER_SENTENCE'] + ' [SEP]'\n",
    "        sarcasm_label = row['Sarcasm']\n",
    "\n",
    "        df_temp = pd.DataFrame([[row['SCENE'], sentence_a, sentence_b, sarcasm_label]], columns=['SCENE', 'SENTENCE_A', 'SENTENCE_B', 'Sarcasm'])\n",
    "        df_new = pd.concat([df_new, df_temp], ignore_index=True)\n",
    "        # Resetting the context and utterance for the next scene\n",
    "        sentence_a = ''\n",
    "        sentence_b = ''\n",
    "        \n",
    "    prev_scene = row['SCENE']\n",
    "\n",
    "df_new[\"SENTENCE_A\"] = df_new[\"SENTENCE_A\"].str.replace('\\n', '')\n",
    "df_new[\"SENTENCE_B\"] = df_new[\"SENTENCE_B\"].str.replace('\\n', '')\n",
    "\n",
    "# print new dataframe\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb6c017",
   "metadata": {},
   "source": [
    "# BERT Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea852ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-cased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def get_embedding(sentence_A, sentence_B, model, tokenizer, device):\n",
    "    marked_text = sentence_A + sentence_B\n",
    "\n",
    "    # Tokenize our sentence with the BERT tokenizer.\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    # Map the token strings to their vocabulary indices.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "    # Mark each token as belonging to sentence \"1\" or \"0\".\n",
    "    segments_ids = [1 if token == \"[SEP]\" else 0 for token in tokenized_text]\n",
    "\n",
    "    # Convert inputs to PyTorch tensors and send them to the same device as the model\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
    "\n",
    "    # Predict hidden states features for each layer\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "    # create a new dimension in the tensor.\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "\n",
    "    # Remove dimension 1, the \"batches\".\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "    # Swap dimensions 0 and 1.\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    # `token_vecs` is a tensor with shape [22 x 768]\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "\n",
    "    # Calculate the average of all token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "\n",
    "    return sentence_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5360b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1202/1202 [00:28<00:00, 42.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Create an empty DataFrame for the embeddings\n",
    "embedding_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each row in the DataFrame and add embeddings as rows to the new DataFrame\n",
    "for i, row in tqdm(df_new.iterrows(), total=df_new.shape[0]):\n",
    "    sentence_A = row['SENTENCE_A']\n",
    "    sentence_B = row['SENTENCE_B']\n",
    "    \n",
    "    embeddings = get_embedding(sentence_A, sentence_B, model, tokenizer, device)\n",
    "    \n",
    "    embedding_df = pd.concat([embedding_df, pd.DataFrame([embeddings.cpu().numpy()])], ignore_index=True)\n",
    "\n",
    "# Rename the columns of the embedding DataFrame\n",
    "embedding_df.columns = [f'Embedding_{i}' for i in range(embedding_df.shape[1])]\n",
    "\n",
    "# Concatenate the embedding DataFrame with the original DataFrame\n",
    "df_new = pd.concat([df_new, embedding_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbde6627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop non necessary features\n",
    "df_new = df_new.drop(['SENTENCE_A', 'SENTENCE_B', 'Sarcasm'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1424c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe\n",
    "df_new.to_csv('text_features_BERT.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53072166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCENE</th>\n",
       "      <th>Embedding_0</th>\n",
       "      <th>Embedding_1</th>\n",
       "      <th>Embedding_2</th>\n",
       "      <th>Embedding_3</th>\n",
       "      <th>Embedding_4</th>\n",
       "      <th>Embedding_5</th>\n",
       "      <th>Embedding_6</th>\n",
       "      <th>Embedding_7</th>\n",
       "      <th>Embedding_8</th>\n",
       "      <th>...</th>\n",
       "      <th>Embedding_758</th>\n",
       "      <th>Embedding_759</th>\n",
       "      <th>Embedding_760</th>\n",
       "      <th>Embedding_761</th>\n",
       "      <th>Embedding_762</th>\n",
       "      <th>Embedding_763</th>\n",
       "      <th>Embedding_764</th>\n",
       "      <th>Embedding_765</th>\n",
       "      <th>Embedding_766</th>\n",
       "      <th>Embedding_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_10004</td>\n",
       "      <td>0.400577</td>\n",
       "      <td>-0.735008</td>\n",
       "      <td>-0.096150</td>\n",
       "      <td>-0.285756</td>\n",
       "      <td>-0.357918</td>\n",
       "      <td>-0.051856</td>\n",
       "      <td>1.045135</td>\n",
       "      <td>-0.481453</td>\n",
       "      <td>-0.091696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231023</td>\n",
       "      <td>0.676469</td>\n",
       "      <td>0.125527</td>\n",
       "      <td>-0.045216</td>\n",
       "      <td>-0.050516</td>\n",
       "      <td>-0.035607</td>\n",
       "      <td>-0.009513</td>\n",
       "      <td>-0.084522</td>\n",
       "      <td>0.603833</td>\n",
       "      <td>0.591910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_10009</td>\n",
       "      <td>0.387123</td>\n",
       "      <td>-0.837304</td>\n",
       "      <td>-0.077900</td>\n",
       "      <td>-0.247002</td>\n",
       "      <td>-0.358525</td>\n",
       "      <td>-0.089530</td>\n",
       "      <td>1.096665</td>\n",
       "      <td>-0.495899</td>\n",
       "      <td>-0.074850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299691</td>\n",
       "      <td>0.699883</td>\n",
       "      <td>0.094027</td>\n",
       "      <td>-0.067608</td>\n",
       "      <td>-0.036613</td>\n",
       "      <td>-0.093318</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>-0.112674</td>\n",
       "      <td>0.624801</td>\n",
       "      <td>0.613933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_1001</td>\n",
       "      <td>0.376343</td>\n",
       "      <td>-0.645923</td>\n",
       "      <td>-0.120487</td>\n",
       "      <td>-0.267022</td>\n",
       "      <td>-0.319736</td>\n",
       "      <td>-0.050790</td>\n",
       "      <td>0.996660</td>\n",
       "      <td>-0.409754</td>\n",
       "      <td>-0.078868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267513</td>\n",
       "      <td>0.632195</td>\n",
       "      <td>0.140556</td>\n",
       "      <td>-0.138602</td>\n",
       "      <td>-0.057374</td>\n",
       "      <td>-0.059396</td>\n",
       "      <td>-0.009998</td>\n",
       "      <td>-0.095549</td>\n",
       "      <td>0.570483</td>\n",
       "      <td>0.570835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_1003</td>\n",
       "      <td>0.366896</td>\n",
       "      <td>-0.670176</td>\n",
       "      <td>-0.104165</td>\n",
       "      <td>-0.300600</td>\n",
       "      <td>-0.300686</td>\n",
       "      <td>-0.042529</td>\n",
       "      <td>0.994088</td>\n",
       "      <td>-0.427367</td>\n",
       "      <td>-0.069317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254600</td>\n",
       "      <td>0.610260</td>\n",
       "      <td>0.107198</td>\n",
       "      <td>-0.092323</td>\n",
       "      <td>-0.042515</td>\n",
       "      <td>-0.088271</td>\n",
       "      <td>-0.008831</td>\n",
       "      <td>-0.111850</td>\n",
       "      <td>0.573721</td>\n",
       "      <td>0.568279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_10190</td>\n",
       "      <td>0.405070</td>\n",
       "      <td>-0.688916</td>\n",
       "      <td>-0.153265</td>\n",
       "      <td>-0.233106</td>\n",
       "      <td>-0.311845</td>\n",
       "      <td>-0.056022</td>\n",
       "      <td>0.998371</td>\n",
       "      <td>-0.423859</td>\n",
       "      <td>-0.054147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254542</td>\n",
       "      <td>0.631909</td>\n",
       "      <td>0.132351</td>\n",
       "      <td>-0.105029</td>\n",
       "      <td>-0.070631</td>\n",
       "      <td>-0.131713</td>\n",
       "      <td>-0.016279</td>\n",
       "      <td>-0.082275</td>\n",
       "      <td>0.584081</td>\n",
       "      <td>0.618788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SCENE  Embedding_0  Embedding_1  Embedding_2  Embedding_3  Embedding_4   \n",
       "0  1_10004     0.400577    -0.735008    -0.096150    -0.285756    -0.357918  \\\n",
       "1  1_10009     0.387123    -0.837304    -0.077900    -0.247002    -0.358525   \n",
       "2   1_1001     0.376343    -0.645923    -0.120487    -0.267022    -0.319736   \n",
       "3   1_1003     0.366896    -0.670176    -0.104165    -0.300600    -0.300686   \n",
       "4  1_10190     0.405070    -0.688916    -0.153265    -0.233106    -0.311845   \n",
       "\n",
       "   Embedding_5  Embedding_6  Embedding_7  Embedding_8  ...  Embedding_758   \n",
       "0    -0.051856     1.045135    -0.481453    -0.091696  ...       0.231023  \\\n",
       "1    -0.089530     1.096665    -0.495899    -0.074850  ...       0.299691   \n",
       "2    -0.050790     0.996660    -0.409754    -0.078868  ...       0.267513   \n",
       "3    -0.042529     0.994088    -0.427367    -0.069317  ...       0.254600   \n",
       "4    -0.056022     0.998371    -0.423859    -0.054147  ...       0.254542   \n",
       "\n",
       "   Embedding_759  Embedding_760  Embedding_761  Embedding_762  Embedding_763   \n",
       "0       0.676469       0.125527      -0.045216      -0.050516      -0.035607  \\\n",
       "1       0.699883       0.094027      -0.067608      -0.036613      -0.093318   \n",
       "2       0.632195       0.140556      -0.138602      -0.057374      -0.059396   \n",
       "3       0.610260       0.107198      -0.092323      -0.042515      -0.088271   \n",
       "4       0.631909       0.132351      -0.105029      -0.070631      -0.131713   \n",
       "\n",
       "   Embedding_764  Embedding_765  Embedding_766  Embedding_767  \n",
       "0      -0.009513      -0.084522       0.603833       0.591910  \n",
       "1       0.002613      -0.112674       0.624801       0.613933  \n",
       "2      -0.009998      -0.095549       0.570483       0.570835  \n",
       "3      -0.008831      -0.111850       0.573721       0.568279  \n",
       "4      -0.016279      -0.082275       0.584081       0.618788  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
